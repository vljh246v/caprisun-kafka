# 2. 빠르게 살펴보는 카프카

## 2.1 데이터 문제

* 비즈니스에서 데이터를 다룰 때 여러 요구 사항이 있을 수 있다.
  * 중앙 저장소로 데이터를 신솓하게 전송할 방법이 필요하다.
  * 오류나 가동 중지로 인한 데이터 손실이 발생하지 않아야 한다.
  * 데이터가 사용되는 곳들의 확장이 쉬워야 한다.
  
## 2.2 카프카를 사용해 데이터 다루기
* 특정 데이터를 여러곳에서 관심을 가지고 있다.
* 시간이 지나면서 특정 데이터를 원하는 서비스와 어플리케이션이 많아지고 복잡해진다. 
* 카프카를 활용해 모든 데이터를 수용하는 하나의 유입 프로세스를 만들 수 있다.
* 카프카는 내고장성을 가진 견고한 발행/구독 시스템이다.
* 하나의 카프카 노드를 브로커라고 부르고, 여러개의 카프카 브로커 서버가 클러스터를 구성한다.
* 카프카는 프로듀서가 작성한 메시지를 토픽에 저장한다.
* 컨슈머는 토픽을 구독하며, 구독한 토픽에 메시지가 있는지를 확인하기 위해 카프카에 접속한다.

## 2.3 카프카 아키텍처

### 2.3.1 카프카는 메시지 브로커다.
* 브로커는 상호 각자 반드시 알 필요가 없는 두 부분을 묶는 중개자 [책 그림 2.4]
* 토픽에 메시지를 저장하고 검색하기 때문에 프로듀서와 컨슈머 간의 직접적인 연결은 없다.
* 또한 프로듀서와 컨슈머에 관한 어떤 상태도 유지하지 않는다.
* 카프카 토픽의 내부 기술은 카프카가 들어오는 레코드를 기록한 파일인 로그다.
* 토픽에 들어오는 메시지의 부하를 관라하기 위해 카프카는 파티션을 사용한다.

### 2.3.2 카프카는 로그다.
* 카프카의 기본 메커니즘은 로그다.
* 카프카의 맥락에서 로그란, '추가만 가능한 시간순으로 완전히 정렬된 레코드 시퀀스'다. [책 그림 2.5]
* 시간과 관련해 순서대로 레코드를 보유하고 있다면 충돌을 해결하거나 다른 머신에 어떤 업데이트를 적용할지 결정하는 것이 단순해진다.
* 카프카의 토픽은 토픽 이름으로 분리된 로그다.
* 토픽은 라벨이 붙은 로그라고 할 수 있다.
* 머신간 로그 복제를 통해 머신이 중지되어도 로그 파일 재생을 통한 복구가 가능하다. 이것이 분산 커밋 로그의 역할이다.

### 2.3.3 카프카에서 로그가 동작하는 방식
* 카프카를 설정할 때 로그 데이터를 저정하는 위치를 지정함
* 각 토픽은 지정된 로그 디렉토리 아래 하위 디렉토리에 매핑됨
* 토픽의 파티션 수만큼 하위 디렉토리 존재 가능
* 토픽은 로그를 나타낸다고도 말할 수 있음
* 토픽 이름은 프로듀서를 통해 카프카에 보내진 메시지가 저장될 로그를 잘 처리할 수 있게 해준다.

### 2.3.4 카프카와 파티션
* 같은 키를 가진 데이터가 동일한 컨슈머에게 순서대로 전송되도록 보장한다.
* 토픽을 파티션으로 분할하면 병렬 스트림으로 토픽에 전달되는 데이터가 분할
* 각 파티션은 로그 자체
* 각 메시지를 로그 끝에 추가하며 메시지는 시간 순서가 지정됨
* 각 메시지에는 할당된 오프셋 번호가 있음
* 파티션 간의 메시지 순서는 보장되지 않지만 각 파티션 내의 메시지 순서는 보장
* 토픽의 메시지를 여러 머신에 분산해 특정 토픽의 용량이 한 서버의 공간에 제한되지 않는다.

### 2.3.5 키에 의한 그룹 데이터 분할
* 카프카는 키/값 쌍으로 데이터를 다룸 [책 그림 2.8]
* 키가 null 이면 카프카 프로듀서는 라운드 로빈 방식으로 선택된 파티션에 레코드를 씀
* 키가 null 이 아닌 경우 카프카는 다음 의사 코드를 통해 파티션을 결정함 : HashCode.(key) % 파티션
* 결과적으로 동일한 키를 가진 레코드가 항상 동일한 파티션에 순서대로 전송됨

### 2.3.6 사용자 정의 파티셔너
* 복합키일경우 특정 키만 파티셔닝에 사용이 필요할 경우 사용자 정의 파티셔너를 사용할수있음 [예제](./code/PurchaseKeyPartitioner.java) 

### 2.3.7 사용자 정의 파티셔너 지정하기
* 작성한 사용자 정의 파티셔너를 프로듀서 설정시 지정한다.
* 프로듀서마다 각기 다른 파티셔너를 사용할 수 있다.

### 2.3.8 정확한 파티션 수 정하기
* 핵심 고려사항은 주어진 토픽에 들어오는 데이터 양이다
* 데이터가 많을수록 처리량을 높이기 위해 더 많은 파티션이 필요하지만 트레이드 오프로 tcp 연결 핸들링과 컨슈머가 레코드를 처리하는 데 걸리는 시간이 늘어난다.

### 2.3.9 분산 로그

* 